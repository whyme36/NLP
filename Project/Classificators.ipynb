{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finished-toddler",
   "metadata": {},
   "source": [
    "# This notebook shows the creation of simple classifiers using the TF-IDF measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d621b6d",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbd7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import ensemble\n",
    "\n",
    "import xgboost, string, re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import simplemma\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-discovery",
   "metadata": {},
   "source": [
    "# Read data, quick analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111e6be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company name, Murr, (address). Bestellt als Vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Register number: Company name, address. Gesell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company name, Hamburg, address. GeschĂ¤ftsansc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Register number: Company name, Bochum, address...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company name, address. GeschĂ¤ftsanschrift: ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Company name, Murr, (address). Bestellt als Vo...      0\n",
       "1  Register number: Company name, address. Gesell...      0\n",
       "2  Company name, Hamburg, address. GeschĂ¤ftsansc...      0\n",
       "3  Register number: Company name, Bochum, address...      1\n",
       "4  Company name, address. GeschĂ¤ftsanschrift: ad...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data.csv',usecols=['text', 'label'], encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62292b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11539, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opponent-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4952"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df.label==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e12b48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Company name, Murr, (address). Bestellt als Vorstand: Firstname, Surname, city, year, einzelvertretungsberechtigt mit der Befugnis, im Namen der Gesellschaft mit sich als Vertreter eines Dritten RechtsgeschĂ¤fte abzuschlieĂźen. Aufgrund Umschreibungsfehlers Vertretungsbefugnis bei der Befreiung von Â§ 181 BGB von Amts wegen berichtigt bei Vorstand:Firstname, Surname, city, year, einzelvertretungsberechtigt mit der Befugnis, im Namen der Gesellschaft mit sich als Vertreter eines Dritten RechtsgeschĂ¤fte abzuschlieĂźen. InlĂ¤ndische GeschĂ¤ftsanschrift: address'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label==0].text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32212fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Register number: Company name,, Sitz vormals: address. Der Sitz der Gesellschaft ist nach Kiel verlegt (Amtsgericht Kiel, HRB 20813 KI). Neue Geschäftsanschrift: new address.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label==1].text[11534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad57137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     string\n",
       "label     Int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.convert_dtypes()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e974bcc",
   "metadata": {},
   "source": [
    "# Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79b90a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data, column_name:str, stopwords_language:str):\n",
    "    \"\"\"\n",
    "    This function preprocess insert german text data, doing:\n",
    "    * drop stopwords form german\n",
    "    * create column with zip and cities\n",
    "    * create column with date of birth\n",
    "    * drop punctation\n",
    "    * lematization of words in text\n",
    "    :param data dataset with text in german:\n",
    "    :return cleared data:\n",
    "    \"\"\"\n",
    "    #rid off punctation\n",
    "    data['cleared text'] = data[column_name].str.replace('[^\\w\\s]', '', regex = True)\n",
    "    \n",
    "    #lematization\n",
    "    langdata = simplemma.load_data('de')\n",
    "    data['cleared text'] = data['cleared text'].apply(lambda x: \" \".join([simplemma.lemmatize(word, langdata) for word in x.split()]))\n",
    "    \n",
    "    # rid off stopwords\n",
    "    nltk.download('stopwords')\n",
    "    stop = stopwords.words(stopwords_language)\n",
    "    data['cleared text'] = data['cleared text'].apply(lambda x: \" \".join(x.lower() for x in x.split() if x not in stop))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459e0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rdjf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleared text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company name, Murr, (address). Bestellt als Vo...</td>\n",
       "      <td>0</td>\n",
       "      <td>company name murren address bestellt vorstand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Register number: Company name, address. Gesell...</td>\n",
       "      <td>0</td>\n",
       "      <td>register number company name address gesellsch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company name, Hamburg, address. GeschĂ¤ftsansc...</td>\n",
       "      <td>0</td>\n",
       "      <td>company name hamburg address geschăftsanschrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Register number: Company name, Bochum, address...</td>\n",
       "      <td>1</td>\n",
       "      <td>register number company name bochum address ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company name, address. GeschĂ¤ftsanschrift: ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>company name address geschăftsanschrift addres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Company name, Murr, (address). Bestellt als Vo...      0   \n",
       "1  Register number: Company name, address. Gesell...      0   \n",
       "2  Company name, Hamburg, address. GeschĂ¤ftsansc...      0   \n",
       "3  Register number: Company name, Bochum, address...      1   \n",
       "4  Company name, address. GeschĂ¤ftsanschrift: ad...      0   \n",
       "\n",
       "                                        cleared text  \n",
       "0  company name murren address bestellt vorstand ...  \n",
       "1  register number company name address gesellsch...  \n",
       "2  company name hamburg address geschăftsanschrif...  \n",
       "3  register number company name bochum address ge...  \n",
       "4  company name address geschăftsanschrift addres...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=preprocessing(df, 'text', 'german')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39057d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'company name murren address bestellt vorstand firstname surname city year einzelvertretungsberechtigt befugnis name gesellschaft er|es|sie vertreter dritte rechtsgeschăfte abzuschlieăźen aufgrund umschreibungsfehlers vertretungsbefugnis befreiung â 181 bgb amt wegen berichtigt vorstandfirstname surname city year einzelvertretungsberechtigt befugnis name gesellschaft er|es|sie vertreter dritte rechtsgeschăfte abzuschlieăźen inlăndische geschăftsanschrift address'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label==0]['cleared text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7502be2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'register number company name sitz vormals address sitz gesellschaft kiel vorverlegen amtsgericht kiel hrb 20813 ki neu geschäftsanschrift new address'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label==1]['cleared text'][11534]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326d4ba",
   "metadata": {},
   "source": [
    "# Create TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6024a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df['text'], df['label'],random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "perceived-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change type of data, idk why classifer read it like str\n",
    "train_y=train_y.astype(int)\n",
    "test_y=test_y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3a8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xtest_tfidf =  tfidf_vect.transform(test_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(df['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ordinary-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf_vect, open(f'TFIDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f918b",
   "metadata": {},
   "source": [
    "# Function to train calssificators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6781b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_vtest, test_y,is_neural_net=False,save=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # Save the trained model as a pickle string.\n",
    "    if save:\n",
    "        pickle.dump(classifier, open(f'{str(classifier).split(\"(\")[0]}.pkl', 'wb'))\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_vtest)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(predictions, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bdc61",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f9c200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, WordLevel TF-IDF:  0.9102253032928943\n",
      "NB, N-Gram Vectors:  0.9206239168110919\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf, test_y, save = True)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram, test_y)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb13c57",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f10f10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, WordLevel TF-IDF:  0.9487001733102253\n",
      "LR, N-Gram Vectors:  0.9608318890814558\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(random_state=123), xtrain_tfidf, train_y, xtest_tfidf, test_y, save = True)\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(random_state=123), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram,test_y)\n",
    "print (\"LR, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a54ccb",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4ba41db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, WordLevel TF-IDF: 0.963258232235702\n",
      "SVM, N-Gram Vectors:  0.9688041594454073\n"
     ]
    }
   ],
   "source": [
    "# SVM on Word Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(random_state=123), xtrain_tfidf, train_y, xtest_tfidf, test_y, save = True)\n",
    "print (\"SVM, WordLevel TF-IDF:\", accuracy)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(random_state=123), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram, test_y)\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e04ed7",
   "metadata": {},
   "source": [
    "# Random Forest \n",
    "Random Forest has the possibility to show which words the model pays special attention to when classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sought-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_RF(classifier, feature_vector_train, label, feature_vector_vtest, test_y, is_neural_net = False, save = False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # Save the trained model as a pickle string.\n",
    "    if save:\n",
    "        pickle.dump(classifier, open(f'{str(classifier).split(\"(\")[0]}.pkl', 'wb'))\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_vtest)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    importances = classifier.feature_importances_\n",
    "    return metrics.accuracy_score(predictions, test_y),importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43d3fa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, WordLevel TF-IDF:  0.9809358752166378\n",
      "RF, N-Gram Vectors:  0.9660311958405546\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors #wizualziacja drzewa\n",
    "accuracy,importances= train_model_RF(ensemble.RandomForestClassifier(n_estimators=50,random_state=123), xtrain_tfidf, train_y, xtest_tfidf, test_y, save = True)\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "# RF on Ngram Level TF IDF Vectors\n",
    "accuracy,im2 = train_model_RF(ensemble.RandomForestClassifier(n_estimators=50,random_state=123), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram, test_y)\n",
    "print (\"RF, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "solid-sense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word_tfidf</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>geschäftsanschrift</td>\n",
       "      <td>0.166230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>änderung</td>\n",
       "      <td>0.026122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>die</td>\n",
       "      <td>0.023965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>nach</td>\n",
       "      <td>0.022940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>verlegt</td>\n",
       "      <td>0.017289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word_tfidf  importance\n",
       "2314  geschäftsanschrift    0.166230\n",
       "4974            änderung    0.026122\n",
       "1695                 die    0.023965\n",
       "3461                nach    0.022940\n",
       "4545             verlegt    0.017289"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IFD model importance of words\n",
    "df_importance=pd.DataFrame({'Word_tfidf':tfidf_vect.get_feature_names(), 'importance':importances})\n",
    "df_importance.sort_values(by = ['importance'], ascending = False)[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "simple-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word_ngram</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>zur geschäftsanschrift</td>\n",
       "      <td>0.024732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>der sitz</td>\n",
       "      <td>0.018045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>geänderte geschäftsanschrift</td>\n",
       "      <td>0.016139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>nach änderung</td>\n",
       "      <td>0.014738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>der geschäftsanschrift</td>\n",
       "      <td>0.014082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Word_ngram  importance\n",
       "4918        zur geschäftsanschrift    0.024732\n",
       "1732                      der sitz    0.018045\n",
       "2838  geänderte geschäftsanschrift    0.016139\n",
       "3646                 nach änderung    0.014738\n",
       "1669        der geschäftsanschrift    0.014082"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IFD n-gram model importance of words\n",
    "df_importance=pd.DataFrame({'Word_ngram':tfidf_vect_ngram.get_feature_names(), 'importance':im2})\n",
    "df_importance.sort_values(by = ['importance'],ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c1a6d3",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "349025fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, WordLevel TF-IDF:  0.9889081455805893\n",
      "[18:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Xgb, N-Gram Vectors:  0.9746967071057192\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xtest_tfidf.tocsc(), test_y, save = True)\n",
    "print (\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(), train_y, xtest_tfidf_ngram.tocsc(), test_y)\n",
    "print (\"Xgb, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d9ed3",
   "metadata": {},
   "source": [
    "# Check pickle\n",
    "Below shows how to save and load ML models in pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "import pickle\n",
    "pickle.dump(classifier, open(f'name_of_file.pkl', 'wb'))\n",
    "classifier=pickle.load(open('name_of_file.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d856b6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889081455805893"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether the model has been saved correctly\n",
    "pickled_model = pickle.load(open('XGBClassifier.pkl', 'rb'))\n",
    "predictions=pickled_model.predict(xtest_tfidf)\n",
    "metrics.accuracy_score(predictions, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f845e5",
   "metadata": {},
   "source": [
    "# Check publication as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "961bd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(text, stopwords_language):\n",
    "    #rid off punctation\n",
    "    text= re.sub(r'[^\\w\\s]', \"\", text)\n",
    "    lematization = ''\n",
    "    \n",
    "    #lematization\n",
    "    langdata = simplemma.load_data('de')\n",
    "    for word in text.split():\n",
    "        lematization += ' '+simplemma.lemmatize(word, langdata)\n",
    "        \n",
    "    # rid off stopwords\n",
    "    nltk.download('stopwords')\n",
    "    stop = stopwords.words(stopwords_language)\n",
    "    text_cleared = ''\n",
    "    for word in lematization.split():\n",
    "        if word not in stop:\n",
    "            text_cleared += \" \" + word.lower()   \n",
    "    return text_cleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79debd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_change = 'Register number, company name, address. Firma geändert, nun: Neue Firma: new company name. Sitz verlegt, nun: Neuer Sitz: Witten. Geändert, nun: Geschäftsanschrift: new address.'\n",
    "publication_no_change = 'Register number, company name, address. Rechtsverhaeltnis: Die Gesellschaft ist auf Grund des Verschmelzungsvertrages vom 02.07.2015 und der Zustimmungsbeschlüsse vom 20.07.2015 durch Übertragung ihres Vermögens als Ganzes unter Auflösung ohne Abwicklung auf die company name verschmolzen. Die Verschmelzung ist mit der gleichzeitig erfolgten Eintragung in das Register des Sitzes des übernehmenden Rechtsträgers wirksam geworden. Die Firma ist erloschen. Als nicht eingetragen wird veröffentlicht: Den Gläubigern der an der Verschmelzung beteiligten Rechtsträger ist, wenn sie binnen sechs Monaten nach dem Tag, an dem die Eintragung der Verschmelzung in das Register des Sitzes desjenigen Rechtsträgers, dessen Gläubiger sie sind, als bekannt gemacht gilt, ihren Anspruch nach Grund und Höhe schriftlich anmelden, Sicherheit zu leisten, soweit sie nicht Befriedigung verlangen können. Dieses Recht steht den Gläubigern jedoch nur zu, wenn sie glaubhaft machen, dass durch die Verschmelzung die Erfüllung ihrer Forderung gefährdet wird.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "688d6e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rdjf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' register number company name address firma geändert neu firma new company name sitz vorverlegen neu sitz witten geändert geschäftsanschrift new address'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_text(publication_change, 'german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "813a27fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rdjf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=pickled_model.predict(tfidf_vect.transform([preprocessing_text(publication_change, 'german')]))\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4632bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rdjf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=pickled_model.predict(tfidf_vect.transform([preprocessing_text(publication_no_change, 'german')]))\n",
    "prediction[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
